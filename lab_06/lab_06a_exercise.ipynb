{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tTx7jTzmXPgE"
      },
      "source": [
        "# Exercises"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldkUOeiQ6WZT"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8TBoiGOBD7Y"
      },
      "source": [
        "#### Setup Google Cloud Vision API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FcPJViA5AZly"
      },
      "outputs": [],
      "source": [
        "# Install the Google Cloud Vision library that allows us to make request to the Google Cloud Vision API\n",
        "!pip install google-cloud-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MpkJiD3bAiNk"
      },
      "outputs": [],
      "source": [
        "# Import the libraries\n",
        "from google.cloud import vision\n",
        "import os\n",
        "import json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ukSR9KOmAjBi"
      },
      "outputs": [],
      "source": [
        "credentials = {\n",
        "##COPY the content of the JSON file here ##\n",
        "\n",
        " }\n",
        "\n",
        "json_credentials = json.dumps(credentials)\n",
        "\n",
        "with open('My Project-543e6ed386ee.json','w') as outfile:\n",
        "  outfile.write(json_credentials)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aL69KxHbAqQU"
      },
      "outputs": [],
      "source": [
        "# Using the GOOGLE_APPLICATION_CREDENTIALS environment variable the location of a credential JSON file can be provided.\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'My Project-543e6ed386ee.json'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xVYpW4DRAwfX"
      },
      "outputs": [],
      "source": [
        "# Instantiate the client (this only works with the credantials correctly set)\n",
        "client = vision.ImageAnnotatorClient()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wlr4Xsw6O6m"
      },
      "source": [
        "#### Setup OpenAI Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JnwxIEC1-7z9"
      },
      "outputs": [],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C5Wlh7JM_Sv9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from pathlib import Path\n",
        "from openai import OpenAI\n",
        "import IPython.display as ipd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uQdHtdCVi5aP"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY'] = 'COPY THE API_KEY HERE'\n",
        "openAIclient = OpenAI()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_6c7PJLEp2l4"
      },
      "source": [
        "### Exercise 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkfS9w67nwYW"
      },
      "source": [
        "1) Use Google Cloud Vision API for emotion detection.\n",
        "\n",
        "2) Use Chat Completions API to generate a poem which fits the emotions detected in the face.\n",
        "\n",
        "3) Use Images API to create a fitting image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GBCDuP9h9M0k"
      },
      "source": [
        "#### Face Dectection and Extraction of Face Properties  with Google Cloud Vision API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rC5sSgg5pIfQ"
      },
      "outputs": [],
      "source": [
        "# Here we use a publicly-accessible URL as image URI\n",
        "# Before making the request we open the image via its uri and display it\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "uri = 'https://www.indiewire.com/wp-content/uploads/2016/08/20140216-131646.jpg'\n",
        "\n",
        "# put your code here to display the image #\n",
        "# YOUR CODE (START)\n",
        "\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vcaNOXYvpPRw"
      },
      "outputs": [],
      "source": [
        "# Set image to be analyzed by Google Vision\n",
        "\n",
        "# YOUR CODE (START)\n",
        "\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yU3WeiOnoBXT"
      },
      "outputs": [],
      "source": [
        "#### FACE DETECTION ######\n",
        "## Use the face detection feature of the Google Cloud API and store the result in response_faces\n",
        "\n",
        "# YOUR CODE (START)\n",
        "\n",
        "response_faces =\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzwjRFRQoBSk"
      },
      "outputs": [],
      "source": [
        "## Access the first face and store it in a variable face\n",
        "\n",
        "# YOUR CODE (START)\n",
        "\n",
        "face =\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g9AMgt_Iok9-"
      },
      "outputs": [],
      "source": [
        "# Names of likelihood from google.cloud.vision.enums\n",
        "likelihood_name = ('UNKNOWN', 'VERY_UNLIKELY', 'UNLIKELY', 'POSSIBLE',\n",
        "                       'LIKELY', 'VERY_LIKELY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKUlLupYokJ3"
      },
      "outputs": [],
      "source": [
        "# Create a function creating a string with all likelihood ratings for the different emotions\n",
        "def hasEmotions(face):\n",
        "      emotionStr = # Add your code here to compose the string\n",
        "\n",
        "      return emotionStr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gfI1zG4doXFZ"
      },
      "outputs": [],
      "source": [
        "# Call the function hasEmotions(face) and store the result in variable emotionText\n",
        "\n",
        "emotionText = # Add your code here\n",
        "\n",
        "print(emotionText)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wk8HVDuh-S8F"
      },
      "source": [
        "#### Text Generation using OpenAI Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmog7IwcortR"
      },
      "outputs": [],
      "source": [
        "# Use OpenAI Chat Completions API with a system message to tell the system how to behave, i.e., create a poem fitting the mood, and what input it gets\n",
        "# Use a user message to pass the emotionText\n",
        "# Store the response of the API call in a variable response\n",
        "\n",
        "response = # Add your code here\n",
        "poem = # Add your code to extract the message content from the response and store it in variable poem\n",
        "\n",
        "print(poem)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-fO9lQa-lg_"
      },
      "source": [
        "#### Image Generation using OpenAI Images API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "msdM2Nhtp83P"
      },
      "outputs": [],
      "source": [
        "# Write a function called generateImage which takes as input a prompt and generates an image\n",
        "# Use for image generation OpenAI Image API with model=\"dall-e-3\"\n",
        "def generateImage(prompt):\n",
        "\n",
        "  # YOUR CODE (START)\n",
        "\n",
        "  response =\n",
        "\n",
        "  # YOUR CODE (END)\n",
        "\n",
        "  return response.data[0].url"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5oqqXubRqLpz"
      },
      "outputs": [],
      "source": [
        "# Add your code here to call the function generateImage\n",
        "# Pass the previously generated poem as promt\n",
        "poem_Image_Uri = # add your code here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhWK4fs3qON_"
      },
      "outputs": [],
      "source": [
        "# Show the generated image given its URL\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "# YOUR CODE (START)\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pDCix9fypyiB"
      },
      "source": [
        "### Exercise 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ge3pfrdJmcpw"
      },
      "source": [
        "1) Use Google Vision Cloud API for landmark detection.\n",
        "\n",
        "2) Feed the landmark description including the latitude and longitute into Chat Completions API.\n",
        "\n",
        "3) Prompt the Chat Completions API to behave like a Swiss travel guide and explain that the input will be a landmark description including latitude and longitude. Ask Chat Completions API to briefly explain the landmark, make suggestions for activities, and provide a funny fact."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3F12uQPnBHy-"
      },
      "source": [
        "#### Landmark Detection Using Google Cloud Vision API\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9fnElrBYi6Lu"
      },
      "outputs": [],
      "source": [
        "# Here we use a publicly-accessible URL as image URI\n",
        "# Before making the request we open the image via its uri and display it\n",
        "\n",
        "from PIL import Image\n",
        "import urllib.request\n",
        "\n",
        "uri = 'https://upload.wikimedia.org/wikipedia/commons/e/ee/Joachim_Vadian_Denkmal%2C_St._Gallen.jpg'\n",
        "\n",
        "# put your code here to display the image #\n",
        "# YOUR CODE (START)\n",
        "\n",
        "\n",
        "# YOUR CODE (END)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bFX_ipyg4r2d"
      },
      "outputs": [],
      "source": [
        "# Set image to be analyzed by Google Vision\n",
        "# YOUR CODE (START)\n",
        "\n",
        "\n",
        "# YOUR CODE (END)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z-rusgi4nv_"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYhanMXRi_nz"
      },
      "outputs": [],
      "source": [
        "#### LANDMARK DETECTION ######\n",
        "\n",
        "# use google cloud vision API for landmark detection; store the result of the API call in variable response_image\n",
        "\n",
        "# YOUR CODE (START)\n",
        "response_image =\n",
        "# YOUR CODE (END)\n",
        "\n",
        "\n",
        "# extract from response_image.landmark_annotations the first landmark including its description\n",
        "\n",
        "# YOUR CODE (START)\n",
        "landmark =\n",
        "decription =\n",
        "# YOUR CODE (END)\n",
        "\n",
        "# extract the first location including its latitude and its longitude\n",
        "\n",
        "# YOUR CODE (START)\n",
        "location =\n",
        "latitude =\n",
        "longitude =\n",
        "# YOUR CODE (END)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pi4gKgzWBVAl"
      },
      "source": [
        "#### Generate Landmark Explanation Using Chat Completions API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4s5-QJRRETLL"
      },
      "outputs": [],
      "source": [
        "originalText = # add here a string with the landmark description as well as the latitude and longitude of the landmark\n",
        "\n",
        "# The string with the landmark description as well as the latitude and longitude of the landmark should look as follows:\n",
        "# Vadian Denkmal: Latitude 47.42574729999999: Longitude 9.3761417\n",
        "\n",
        "print(originalText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PtjN11gZjYlw"
      },
      "outputs": [],
      "source": [
        "# Call to Chat Completions API\n",
        "# Use a system message to tell the model how to behave\n",
        "# Pass the landmark description including longitude and latitude as part of the user message\n",
        "\n",
        "response =\n",
        "\n",
        "print(response.choices[0].message.content)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}